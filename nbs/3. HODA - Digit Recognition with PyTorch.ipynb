{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_CNN_HODA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTr9C_4kTvML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import io\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqkv8Hg8TwhE",
        "colab_type": "code",
        "outputId": "b6301ce4-f29f-4d28-c24b-d8222943c8fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# DownloadDataset\n",
        "import urllib.request\n",
        "url = 'http://farsiocr.ir/Archive/DigitDB.zip'\n",
        "urllib.request.urlretrieve(url, './Data.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./Data.zip', <http.client.HTTPMessage at 0x7f7dfd6200b8>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5917D18-T0a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "address = './Data.zip'\n",
        "d = ZipFile(address, 'r')\n",
        "d.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1vcUQJsT0dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/amir-saniyan/HodaDatasetReader\n",
        "import struct\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def __convert_to_one_hot(vector, num_classes):\n",
        "    result = np.zeros(shape=[len(vector), num_classes])\n",
        "    result[np.arange(len(vector)), vector] = 1\n",
        "    return result\n",
        "\n",
        "\n",
        "def __resize_image(src_image, dst_image_height, dst_image_width):\n",
        "    src_image_height = src_image.shape[0]\n",
        "    src_image_width = src_image.shape[1]\n",
        "\n",
        "    if src_image_height > dst_image_height or src_image_width > dst_image_width:\n",
        "        height_scale = dst_image_height / src_image_height\n",
        "        width_scale = dst_image_width / src_image_width\n",
        "        scale = min(height_scale, width_scale)\n",
        "        img = cv2.resize(src=src_image, dsize=(0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
        "    else:\n",
        "        img = src_image\n",
        "\n",
        "    img_height = img.shape[0]\n",
        "    img_width = img.shape[1]\n",
        "\n",
        "    dst_image = np.zeros(shape=[dst_image_height, dst_image_width], dtype=np.uint8)\n",
        "\n",
        "    y_offset = (dst_image_height - img_height) // 2\n",
        "    x_offset = (dst_image_width - img_width) // 2\n",
        "\n",
        "    dst_image[y_offset:y_offset+img_height, x_offset:x_offset+img_width] = img\n",
        "\n",
        "    return dst_image\n",
        "\n",
        "\n",
        "def read_hoda_cdb(file_name):\n",
        "    with open(file_name, 'rb') as binary_file:\n",
        "\n",
        "        data = binary_file.read()\n",
        "\n",
        "        offset = 0\n",
        "\n",
        "        # read private header\n",
        "\n",
        "        yy = struct.unpack_from('H', data, offset)[0]\n",
        "        offset += 2\n",
        "\n",
        "        m = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        d = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        H = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        W = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        TotalRec = struct.unpack_from('I', data, offset)[0]\n",
        "        offset += 4\n",
        "\n",
        "        LetterCount = struct.unpack_from('128I', data, offset)\n",
        "        offset += 128 * 4\n",
        "\n",
        "        imgType = struct.unpack_from('B', data, offset)[0]  # 0: binary, 1: gray\n",
        "        offset += 1\n",
        "\n",
        "        Comments = struct.unpack_from('256c', data, offset)\n",
        "        offset += 256 * 1\n",
        "\n",
        "        Reserved = struct.unpack_from('245c', data, offset)\n",
        "        offset += 245 * 1\n",
        "\n",
        "        if (W > 0) and (H > 0):\n",
        "            normal = True\n",
        "        else:\n",
        "            normal = False\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(TotalRec):\n",
        "\n",
        "            StartByte = struct.unpack_from('B', data, offset)[0]  # must be 0xff\n",
        "            offset += 1\n",
        "\n",
        "            label = struct.unpack_from('B', data, offset)[0]\n",
        "            offset += 1\n",
        "\n",
        "            if not normal:\n",
        "                W = struct.unpack_from('B', data, offset)[0]\n",
        "                offset += 1\n",
        "\n",
        "                H = struct.unpack_from('B', data, offset)[0]\n",
        "                offset += 1\n",
        "\n",
        "            ByteCount = struct.unpack_from('H', data, offset)[0]\n",
        "            offset += 2\n",
        "\n",
        "            image = np.zeros(shape=[H, W], dtype=np.uint8)\n",
        "\n",
        "            if imgType == 0:\n",
        "                # Binary\n",
        "                for y in range(H):\n",
        "                    bWhite = True\n",
        "                    counter = 0\n",
        "                    while counter < W:\n",
        "                        WBcount = struct.unpack_from('B', data, offset)[0]\n",
        "                        offset += 1\n",
        "                        # x = 0\n",
        "                        # while x < WBcount:\n",
        "                        #     if bWhite:\n",
        "                        #         image[y, x + counter] = 0  # Background\n",
        "                        #     else:\n",
        "                        #         image[y, x + counter] = 255  # ForeGround\n",
        "                        #     x += 1\n",
        "                        if bWhite:\n",
        "                            image[y, counter:counter + WBcount] = 0  # Background\n",
        "                        else:\n",
        "                            image[y, counter:counter + WBcount] = 255  # ForeGround\n",
        "                        bWhite = not bWhite  # black white black white ...\n",
        "                        counter += WBcount\n",
        "            else:\n",
        "                # GrayScale mode\n",
        "                data = struct.unpack_from('{}B'.format(W * H), data, offset)\n",
        "                offset += W * H\n",
        "                image = np.asarray(data, dtype=np.uint8).reshape([W, H]).T\n",
        "\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "\n",
        "def read_hoda_dataset(dataset_path, images_height=32, images_width=32, one_hot=False, reshape=True):\n",
        "    images, labels = read_hoda_cdb(dataset_path)\n",
        "    assert len(images) == len(labels)\n",
        "\n",
        "    X = np.zeros(shape=[len(images), images_height, images_width], dtype=np.float32)\n",
        "    Y = np.zeros(shape=[len(labels)], dtype=np.int)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        image = images[i]\n",
        "        # Image resizing.\n",
        "        image = __resize_image(src_image=image, dst_image_height=images_height, dst_image_width=images_width)\n",
        "        # Image normalization.\n",
        "        image = image / 255\n",
        "        # Image binarization.\n",
        "        image = np.where(image >= 0.5, 1, 0)\n",
        "        # Image.\n",
        "        X[i] = image\n",
        "        # Label.\n",
        "        Y[i] = labels[i]\n",
        "\n",
        "    if one_hot:\n",
        "        Y = __convert_to_one_hot(Y, 10).astype(dtype=np.float32)\n",
        "    else:\n",
        "        Y = Y.astype(dtype=np.float32)\n",
        "\n",
        "    if reshape:\n",
        "        X = X.reshape(-1, images_height * images_width)\n",
        "    else:\n",
        "        X = X.reshape(-1, images_height, images_width, 1)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jF7X_fFT0gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images, train_labels = read_hoda_cdb('./Train 60000.cdb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU_rtVWGT0lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_original = np.squeeze(train_images[:1000])\n",
        "y_train = np.squeeze(train_labels[:1000])\n",
        "X_test_original = np.squeeze(train_images[1000:1200])\n",
        "y_test = np.squeeze(train_labels[1000:1200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mcUAw8-T0pt",
        "colab_type": "code",
        "outputId": "00109d03-0124-4b55-8fef-fd50f25830dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(X_train_original[999], cmap = 'gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7df4dd0080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHYAAAD8CAYAAACijFCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACM1JREFUeJzt3V+IXGcdxvHvY9qgaKHG1hCSaIsG\nJQiNbAkVe1GLkbU3URBpL6QXgXhhQcGbUC+s4EWFavFChKiludDG4h8MIVhjCNQLqcnW2qapNjG0\nNGGbEGoxvbEm/Xkx78JmzcyenXPOnDO/fT4w7MzZM3Pe5dn3zHtmzu+8iggsn3d13QBrh4NNysEm\n5WCTcrBJOdikHGxSDjYpB5vUdXWeLGkW+CGwBvhpRDy8zPrX/JhrZmamTjMqmZuba30bE3IxIm5e\nbiWN+5GipDXAy8AO4CxwDLgvIk6OeM41NzaJjzUltb6NCZmLiNuXW6nOrng7cDoizkTE28B+YGeN\n17MG1Ql2I/Daosdny7KrSNot6bik4zW2ZStU6z22iojYC+yF4btia16dHnsO2Lzo8aayzHqgTrDH\ngC2SbpW0FrgXODDqCTMzM0TE/90m4Vrbzfxd9Ni74oi4LOkB4CkGhzuPRcSLjbXMaqn1HhsRh4BD\nDbXFGuRPnpJysEk52KQcbFIONikHm5SDTcrBJuVgk3KwSTnYpBxsUg42KQeblINNysEm1frJbH2R\n6LziStxjk3KwSTnYpBxsUg42qbGr7QAkvQJcAq4Al5erAnO1XSMqVds1cbjzmYi42MDrWIO8K06q\nbrAB/EHSnKTdTTTImlF3V3xnRJyT9EHgsKS/R8TTi1cogTv0Cas1eLrqhaSHgLci4pER63jwVF+7\nlyqQ9F5JNyzcBz4HnBj39axZdXbF64Hflp5wHfCLiPh9I62y2urUx54BbmuwLdYgH+4k5WCTcrBJ\nOdikVs2pMcOOlRMd317FPTYpB5uUg03KwSblYJNaNaPiYUZ9szTNI2b32KQcbFIONikHm5SDTcrB\nJuVgk3KwSTnYpBxsUg42qWWDlfSYpAuSTixatk7SYUmnys/3t9tMW6kqPfZxYHbJsj3AkYjYAhwp\nj61Hlg22FFm9sWTxTmBfub8P+ELD7bKaxn2PXR8R8+X+6wzKPaxHan8fGxExapZJl1F2Y9wee17S\nBoDy88KwFSNib0TcXqX0z5ozbrAHgPvL/fuB3zXTHGtKlcOdJ4A/Ax+TdFbSLuBhYIekU8Bny+N0\npnlq0sYq2ittrMOK9iZ1fC5UuxXt1m8ONikHm5SDTaoXJ4wPG4xM26CqT9xjk3KwSTnYpBxsUg42\nqV6MiqfNNFyoxD02KQeblINNysEm5WCTcrBJOdikHGxSDjYpB5uUg01q3DLKhySdk/Rcud3TRuMk\nDb3ZaOOWUQI8GhHbyu1Qs82yusYto7Seq/Me+4Ck58uu2hXtPTNusD8GPgJsA+aB7w9bUdJuSccl\nHR9zWzaGsYKNiPMRcSUi3gF+Amwfsa7LKDswVrALtbHFF/EslL2z7KkxpYzyLuAmSWeBbwN3SdrG\nYMbnV4CvtthGG0MvyijH0ccqgQkdX7uMcjVzsEk52KQcbFIONikHm5SDTcrBJuVgk3KwSU1tGaUv\nSDKae2xSDjYpB5uUg03KwSY1taPiPurTRUfcY5NysEk52KQcbFIONqkqZZSbJR2VdFLSi5K+XpZ7\nRsoeq9JjLwPfjIitwB3A1yRtxTNS9lqVMsr5iHi23L8EvARsxDNS9tqK3mMl3QJ8EngGz0jZa5U/\neZL0PuDXwDci4t+LP00ZNSOlZ6PsRqUeK+l6BqH+PCJ+UxZXmpHSZZTdqDIqFvAz4KWI+MGiX3lG\nyh5bttpO0p3An4AXgHfK4gcZvM8+CXwIeBX4ckSMvFZFk9V2w/Tx1JiGvwSoVG03tWWUwzjYAX/y\nlJSDTcrBJuVgk0p3aoxPJB9wj03KwSblYJNysEk52KTSjYr7aNSIvK2Tyd1jk3KwSTnYpBxsUg42\nKQeblINNysEm5WCTcrBJOdik6pRRTmRGShtPlS8BFsoon5V0AzAn6XD53aMR8Uh7zbNxLRtsqaib\nL/cvSVooo7Qeq1NGCZ6RsrcqB7u0jJKKM1J6NspuVKrdKWWUB4GnllTcLfz+FuBgRHximdfp7BzQ\nvp5+OsYX7c3U7gwro/SMlP1WZVT8aeArwAuSnivLHgTum6YZKVfbieTpyihXqutgO9sV23RysEk5\n2KQcbFIONikHm5SDTcrBJuVgk3KwSbmMsmNtzdXjHpuUg03KwSblYJNysEk52KQcbFIONikHm5SD\nTcrBJlXlhPF3S/qLpL+VMsrvlOW3SnpG0mlJv5S0tv3mWlVVeux/gLsj4jYGdTqzku4AvsegjPKj\nwL+AXe0101aqymyUERFvlYfXl1sAdwO/Kss9G2XPVJ3bbk0p77gAHAb+CbwZEZfLKmdxzWyvVAo2\nIq5ExDZgE7Ad+HjVDbiMshsrGhVHxJvAUeBTwI2SFr6o3wScG/Icz0bZgSqj4psl3VjuvwfYwWDW\n56PAl8pqno2yZ6qcGrMB2CdpDYN/hCcj4qCkk8B+Sd8F/sqghnbqjDoFpetKvDpWfRnlKF0GO+If\nzmWUq5mDTcrBJuVgk/IJ4yNM8wVJ3GOTcrBJOdikHGxSDjYpB5uUD3d6qm7drHtsUg42KQeblINN\nysEm5VHxGCbx5YCvGmPX5GCTcrBJOdikHGxSkx4VXwReLfdvKo/TqDiSrft3f7hSW7o6f0fS8dVY\nzzOpv9u74qQcbFJdBru3w213aSJ/d2fvsdYu74qT6iRYSbOS/lEuJbSnizZMQpni/IKkE4uWrZN0\nWNKp8rOVKdAnHmwpoP4R8HlgK4N5aLdOuh0T8jgwu2TZHuBIRGwBjpTHjeuix24HTkfEmYh4G9gP\n7OygHa2LiKeBN5Ys3sng8knQ4mWUugh2I/Daoser7VJC6yNivtx/HVjfxkY8eOpQDA5JWjks6SLY\nc8DmRY+HXkooqfOSNgCUnxfa2EgXwR4DtpSLbK4F7gUOdNCOrhxgcPkkaPMyShEx8RtwD/Ayg0v3\nfauLNkzo73wCmAf+y2AssQv4AIPR8Cngj8C6NrbtT56S8uApKQeblINNysEm5WCTcrBJOdikHGxS\n/wN6H/2PN2iF8AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9186L45nT0sU",
        "colab_type": "code",
        "outputId": "d8871b73-2273-44cf-b0d6-ec96e6f467fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_original[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcNaH5lST0ou",
        "colab_type": "code",
        "outputId": "587aeea8-07f4-42da-f54d-f697a5769599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "def show_image(i = 70, data = X_train_original, label = y_train):\n",
        "  assert i <= len(data)\n",
        "  image = data[i]\n",
        "  lab = label[i]\n",
        "  plt.imshow(image, cmap = 'gray')\n",
        "  print(f\"Label for {i}th image is: {lab}\")\n",
        "\n",
        "show_image()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label for 70th image is: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD8CAYAAABw8JiyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188-77YwT0kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resizing\n",
        "X_train_5b5 = [resize(img, (25, 20)) for img in X_train_original]\n",
        "X_test_5b5 = [resize(img, (25, 20)) for img in X_test_original]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88qJKXjGUK60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshaping\n",
        "X_train = [x.reshape(-1) for x in X_train_5b5]\n",
        "X_test = [x.reshape(-1) for x in X_test_5b5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeza-_2XUK9V",
        "colab_type": "code",
        "outputId": "a281c1be-6be2-4d01-e017-93eff8561fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train[0].shape, X_test[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500,) (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-5MTjbqUPhi",
        "colab_type": "text"
      },
      "source": [
        "# Training Phase\n",
        "\n",
        "https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W84s1jqAUK_3",
        "colab_type": "code",
        "outputId": "88a530f9-6773-467f-c9b1-76139f43f420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip3 install torch -U"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 27kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.1.0\n",
            "    Uninstalling torch-1.1.0:\n",
            "      Successfully uninstalled torch-1.1.0\n",
            "Successfully installed torch-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grgsqWiJULHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Dqf591ULMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(123) # for reproducibility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STiLRVFvULPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list to np arrays\n",
        "X_train = np.array(X_train_5b5)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test_5b5)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd4_w8a31Nqu",
        "colab_type": "code",
        "outputId": "846088e3-e636-4bc0-892e-0749339dbd37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.0425, 0.5275, 1.    , 0.4825, 0.0375, 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.2975, 0.8425, 1.    , 0.8275, 0.2625, 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.1875,\n",
              "        0.7125, 1.    , 1.    , 1.    , 0.6875, 0.1625, 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.375 ,\n",
              "        1.    , 1.    , 1.    , 1.    , 1.    , 0.5275, 0.0825, 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.0275, 0.1   , 0.4375,\n",
              "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 0.275 , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.2475, 0.9   , 0.9375,\n",
              "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 0.275 , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.    , 0.1575, 0.7825, 1.    , 1.    ,\n",
              "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 0.7825, 0.1575,\n",
              "        0.    , 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.0875, 0.6125, 1.    , 1.    , 1.    ,\n",
              "        0.7875, 0.5   , 0.5   , 0.5   , 0.8125, 1.    , 1.    , 0.6125,\n",
              "        0.0875, 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.175 , 1.    , 1.    , 1.    , 0.8875,\n",
              "        0.4025, 0.    , 0.    , 0.    , 0.4375, 0.9025, 1.    , 1.    ,\n",
              "        0.175 , 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.0125, 0.2575, 1.    , 1.    , 0.9675, 0.5625,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.6075, 0.9725, 1.    ,\n",
              "        0.2575, 0.0125, 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.1125, 0.9175, 1.    , 1.    , 0.7075, 0.0625,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.0675, 0.7525, 1.    ,\n",
              "        0.9175, 0.1125, 0.    , 0.    ],\n",
              "       [0.    , 0.0525, 0.7375, 1.    , 1.    , 0.8075, 0.2025, 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.725 , 1.    ,\n",
              "        1.    , 0.7375, 0.0525, 0.    ],\n",
              "       [0.0125, 0.5375, 1.    , 1.    , 1.    , 0.725 , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.725 , 1.    ,\n",
              "        1.    , 1.    , 0.5375, 0.0125],\n",
              "       [0.025 , 1.    , 1.    , 1.    , 0.9325, 0.5075, 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.5075, 0.9325,\n",
              "        1.    , 1.    , 1.    , 0.025 ],\n",
              "       [0.1225, 1.    , 1.    , 0.9825, 0.6975, 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.0525, 0.1   , 0.0375, 0.    , 0.    , 0.6975,\n",
              "        0.9825, 1.    , 1.    , 0.1225],\n",
              "       [0.9025, 1.    , 1.    , 0.8425, 0.0775, 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.4725, 0.9   , 0.3375, 0.    , 0.    , 0.0775,\n",
              "        0.8425, 1.    , 1.    , 0.9025],\n",
              "       [1.    , 1.    , 1.    , 0.825 , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.3325, 0.8575, 1.    , 0.8125, 0.2275, 0.    , 0.    ,\n",
              "        0.825 , 1.    , 1.    , 1.    ],\n",
              "       [1.    , 1.    , 0.9375, 0.4125, 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.2125, 0.7375, 1.    , 1.    , 1.    , 0.325 , 0.    , 0.    ,\n",
              "        0.825 , 1.    , 1.    , 1.    ],\n",
              "       [1.    , 1.    , 0.875 , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.425 , 1.    , 1.    , 1.    , 1.    , 0.325 , 0.    , 0.    ,\n",
              "        0.825 , 1.    , 1.    , 1.    ],\n",
              "       [1.    , 1.    , 0.875 , 0.    , 0.    , 0.    , 0.    , 0.0375,\n",
              "        0.4825, 1.    , 1.    , 1.    , 1.    , 0.3925, 0.0275, 0.0775,\n",
              "        0.8425, 1.    , 1.    , 0.9025],\n",
              "       [1.    , 1.    , 0.875 , 0.    , 0.    , 0.    , 0.    , 0.3375,\n",
              "        0.9425, 1.    , 1.    , 1.    , 1.    , 0.9325, 0.2475, 0.6975,\n",
              "        0.9825, 1.    , 1.    , 0.1225],\n",
              "       [0.3175, 0.9475, 0.2625, 0.    , 0.    , 0.1925, 0.7   , 0.8125,\n",
              "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 0.7825, 0.9325,\n",
              "        1.    , 1.    , 1.    , 0.025 ],\n",
              "       [0.0125, 0.4625, 0.    , 0.    , 0.1125, 0.6375, 1.    , 1.    ,\n",
              "        1.    , 1.    , 1.    , 1.    , 1.    , 0.6625, 0.8625, 1.    ,\n",
              "        1.    , 1.    , 0.5375, 0.0125],\n",
              "       [0.    , 0.    , 0.    , 0.0525, 0.4575, 1.    , 1.    , 1.    ,\n",
              "        0.8725, 0.7   , 0.7   , 0.7   , 0.7   , 0.2275, 0.5075, 0.7   ,\n",
              "        0.7   , 0.7   , 0.0525, 0.    ],\n",
              "       [0.    , 0.    , 0.    , 0.1575, 0.9225, 1.    , 1.    , 1.    ,\n",
              "        0.6175, 0.1   , 0.1   , 0.1   , 0.1   , 0.0325, 0.0725, 0.1   ,\n",
              "        0.1   , 0.1   , 0.0075, 0.    ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1RB_6cVULKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize inputs\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# X_train /= 255.\n",
        "# X_test /= 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5-s-AjNULFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 10\n",
        "\n",
        "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
        "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
        "# torch_y_train = F.one_hot(torch_y_train, 10)\n",
        "\n",
        "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
        "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
        "# torch_y_test = F.one_hot(torch_y_test, 10)\n",
        "\n",
        "# torch train and test sets\n",
        "train = torch.utils.data.TensorDataset(torch_X_train.reshape(-1, 500), torch_y_train)\n",
        "test = torch.utils.data.TensorDataset(torch_X_test.view(-1, 500), torch_y_test)\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqAvKsqULC3",
        "colab_type": "code",
        "outputId": "01334adf-e7f2-4bcc-c065-4b8d0056bae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(torch_X_test[199]), torch_y_test[199]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.image.AxesImage at 0x7f7da186d160>, tensor(5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAD8CAYAAADt/ZE6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny9YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KJhvrP2UfQO",
        "colab_type": "code",
        "outputId": "05de6559-5faf-4fa6-a7b8-b197968b9fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear1 = nn.Linear(500, 256)\n",
        "        self.linear2 = nn.Linear(256, 64)\n",
        "        self.linear3 = nn.Linear(64, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        X = F.relu(self.linear1(x))\n",
        "        X = F.relu(self.linear2(X))\n",
        "        # Find the error!\n",
        "        # return F.softmax(self.linear, dim = 1)\n",
        "\n",
        "\n",
        "        return F.softmax(self.linear3(X), dim = 0)\n",
        "        \n",
        "        \n",
        "        # return F.softmax(self.linear3(X), dim = 1)\n",
        "\n",
        " \n",
        "mlp = MLP()\n",
        "print(mlp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (linear1): Linear(in_features=500, out_features=256, bias=True)\n",
            "  (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owXpYp3iUfS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model, train_loader):\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
        "    error = nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss\n",
        "    EPOCHS = 25\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "          var_X_batch = Variable(X_batch).float() # Switch it to long(), What happens?\n",
        "          var_y_batch = Variable(y_batch).long()\n",
        "          optimizer.zero_grad()\n",
        "          output = model(var_X_batch)\n",
        "          loss = error(output, var_y_batch)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Total correct predictions\n",
        "          predicted = torch.max(output.data, 1)[1] \n",
        "          correct += (predicted == var_y_batch).sum()\n",
        "        # print(predicted)\n",
        "          if batch_idx % 50 == 0:\n",
        "              print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
        "                  epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElX8xdnEUfVW",
        "colab_type": "code",
        "outputId": "e0bec92a-2edf-4ce1-bfb3-b97e5a983301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "fit(mlp, train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 [0/1000 (0%)]\tLoss: 2.302682\t Accuracy:0.000%\n",
            "Epoch : 0 [500/1000 (50%)]\tLoss: 2.301157\t Accuracy:12.745%\n",
            "Epoch : 1 [0/1000 (0%)]\tLoss: 2.299767\t Accuracy:10.000%\n",
            "Epoch : 1 [500/1000 (50%)]\tLoss: 2.290315\t Accuracy:40.392%\n",
            "Epoch : 2 [0/1000 (0%)]\tLoss: 2.287726\t Accuracy:30.000%\n",
            "Epoch : 2 [500/1000 (50%)]\tLoss: 2.245332\t Accuracy:43.922%\n",
            "Epoch : 3 [0/1000 (0%)]\tLoss: 2.209873\t Accuracy:40.000%\n",
            "Epoch : 3 [500/1000 (50%)]\tLoss: 2.181643\t Accuracy:43.529%\n",
            "Epoch : 4 [0/1000 (0%)]\tLoss: 2.181277\t Accuracy:60.000%\n",
            "Epoch : 4 [500/1000 (50%)]\tLoss: 2.161744\t Accuracy:48.824%\n",
            "Epoch : 5 [0/1000 (0%)]\tLoss: 2.047658\t Accuracy:80.000%\n",
            "Epoch : 5 [500/1000 (50%)]\tLoss: 2.055091\t Accuracy:50.784%\n",
            "Epoch : 6 [0/1000 (0%)]\tLoss: 2.071779\t Accuracy:40.000%\n",
            "Epoch : 6 [500/1000 (50%)]\tLoss: 2.069267\t Accuracy:47.255%\n",
            "Epoch : 7 [0/1000 (0%)]\tLoss: 1.934430\t Accuracy:70.000%\n",
            "Epoch : 7 [500/1000 (50%)]\tLoss: 1.979069\t Accuracy:56.471%\n",
            "Epoch : 8 [0/1000 (0%)]\tLoss: 2.113691\t Accuracy:50.000%\n",
            "Epoch : 8 [500/1000 (50%)]\tLoss: 1.960609\t Accuracy:56.078%\n",
            "Epoch : 9 [0/1000 (0%)]\tLoss: 1.942869\t Accuracy:40.000%\n",
            "Epoch : 9 [500/1000 (50%)]\tLoss: 1.894892\t Accuracy:59.608%\n",
            "Epoch : 10 [0/1000 (0%)]\tLoss: 1.890113\t Accuracy:70.000%\n",
            "Epoch : 10 [500/1000 (50%)]\tLoss: 1.891942\t Accuracy:55.686%\n",
            "Epoch : 11 [0/1000 (0%)]\tLoss: 1.893540\t Accuracy:60.000%\n",
            "Epoch : 11 [500/1000 (50%)]\tLoss: 1.875473\t Accuracy:58.039%\n",
            "Epoch : 12 [0/1000 (0%)]\tLoss: 2.036163\t Accuracy:50.000%\n",
            "Epoch : 12 [500/1000 (50%)]\tLoss: 1.927064\t Accuracy:59.608%\n",
            "Epoch : 13 [0/1000 (0%)]\tLoss: 1.999512\t Accuracy:40.000%\n",
            "Epoch : 13 [500/1000 (50%)]\tLoss: 1.844824\t Accuracy:59.020%\n",
            "Epoch : 14 [0/1000 (0%)]\tLoss: 1.780612\t Accuracy:70.000%\n",
            "Epoch : 14 [500/1000 (50%)]\tLoss: 2.008194\t Accuracy:62.941%\n",
            "Epoch : 15 [0/1000 (0%)]\tLoss: 1.987760\t Accuracy:40.000%\n",
            "Epoch : 15 [500/1000 (50%)]\tLoss: 1.966705\t Accuracy:59.020%\n",
            "Epoch : 16 [0/1000 (0%)]\tLoss: 1.713894\t Accuracy:100.000%\n",
            "Epoch : 16 [500/1000 (50%)]\tLoss: 2.026100\t Accuracy:64.314%\n",
            "Epoch : 17 [0/1000 (0%)]\tLoss: 1.898950\t Accuracy:80.000%\n",
            "Epoch : 17 [500/1000 (50%)]\tLoss: 1.914761\t Accuracy:64.902%\n",
            "Epoch : 18 [0/1000 (0%)]\tLoss: 1.765778\t Accuracy:70.000%\n",
            "Epoch : 18 [500/1000 (50%)]\tLoss: 1.945362\t Accuracy:66.275%\n",
            "Epoch : 19 [0/1000 (0%)]\tLoss: 1.973866\t Accuracy:60.000%\n",
            "Epoch : 19 [500/1000 (50%)]\tLoss: 1.914175\t Accuracy:65.882%\n",
            "Epoch : 20 [0/1000 (0%)]\tLoss: 1.881196\t Accuracy:70.000%\n",
            "Epoch : 20 [500/1000 (50%)]\tLoss: 1.945758\t Accuracy:63.529%\n",
            "Epoch : 21 [0/1000 (0%)]\tLoss: 1.885275\t Accuracy:70.000%\n",
            "Epoch : 21 [500/1000 (50%)]\tLoss: 1.814084\t Accuracy:65.294%\n",
            "Epoch : 22 [0/1000 (0%)]\tLoss: 1.888810\t Accuracy:60.000%\n",
            "Epoch : 22 [500/1000 (50%)]\tLoss: 1.957567\t Accuracy:69.020%\n",
            "Epoch : 23 [0/1000 (0%)]\tLoss: 1.881171\t Accuracy:60.000%\n",
            "Epoch : 23 [500/1000 (50%)]\tLoss: 1.967462\t Accuracy:64.706%\n",
            "Epoch : 24 [0/1000 (0%)]\tLoss: 1.931211\t Accuracy:50.000%\n",
            "Epoch : 24 [500/1000 (50%)]\tLoss: 1.847095\t Accuracy:65.882%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwj358Gw4UaY",
        "colab_type": "code",
        "outputId": "3f1ce19c-c252-48c5-875b-f52e62232332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "for a, b in enumerate(test_loader):\n",
        "  # print(a[1])\n",
        "  # xx_test = a[1]\n",
        "  # xy_test = b[1]\n",
        "  # plt.imshow(a[1].view(25, 20))\n",
        "  # print(b)\n",
        "\n",
        "  print(b[1][0])\n",
        "  d = b[0].view(10, 25, 20)[0]\n",
        "  plt.imshow(d)\n",
        "\n",
        "\n",
        "\n",
        "  o = mlp(b[0].type(torch.FloatTensor))\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAD8CAYAAADt/ZE6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw62_uDL3oTK",
        "colab_type": "code",
        "outputId": "976ee0c9-577d-4676-f983-ae36fba5285c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "torch.max(o, dim = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([0.9327, 0.8091, 0.9638, 0.8680, 0.4304, 0.9993, 0.9542, 0.9834, 0.9365,\n",
              "        0.9205], grad_fn=<MaxBackward0>), indices=tensor([9, 3, 4, 8, 1, 6, 2, 9, 0, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le2u-77IUfYO",
        "colab_type": "code",
        "outputId": "d13e4fee-0840-4a22-9ca5-750a7bf0e641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def evaluate(model = mlp):\n",
        "#model = mlp\n",
        "    correct = 0 \n",
        "    for test_imgs, test_labels in test_loader:\n",
        "        #print(test_imgs.shape)\n",
        "        test_imgs = Variable(test_imgs).float()\n",
        "        output = model(test_imgs)\n",
        "        predicted = torch.max(output,1)[1]\n",
        "        correct += (predicted == test_labels).sum()\n",
        "    print(\"Test accuracy:{:.1f}% \".format( float(correct) * 100 / (len(test_loader)*BATCH_SIZE)))\n",
        "evaluate(mlp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:61.0% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QRPPfTjUpoj",
        "colab_type": "text"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iDVyDMaUfcU",
        "colab_type": "code",
        "outputId": "08bd5d03-f111-4ac8-c8cf-84635c97bc59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "torch_X_train_cnn = torch_X_train.view(-1, 1,25,20).float()\n",
        "torch_X_test_cnn = torch_X_test.view(-1,1,25,20).float()\n",
        "print(torch_X_train_cnn.shape)\n",
        "print(torch_X_test_cnn.shape)\n",
        "\n",
        "# Pytorch train and test sets\n",
        "train = torch.utils.data.TensorDataset(torch_X_train_cnn,torch_y_train)\n",
        "test = torch.utils.data.TensorDataset(torch_X_test_cnn,torch_y_test)\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 1, 25, 20])\n",
            "torch.Size([200, 1, 25, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcsqcve7UfhP",
        "colab_type": "code",
        "outputId": "ab724fdd-15f7-4a4d-e9ff-300a0bc372ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # self.conv1 = nn.Conv2d(1, 32, kernel_size = 3)\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(32,64, kernel_size=3)\n",
        "        self.fc1 = nn.Linear(768, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        # x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
        "        # x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = x.view(-1,768 )\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim = 0)\n",
        " \n",
        "cnn = CNN()\n",
        "print(cnn)\n",
        "\n",
        "it = iter(train_loader)\n",
        "X_batch, y_batch = next(it)\n",
        "print(cnn.forward(X_batch))\n",
        "X_batch, _ = next(it)\n",
        "print(cnn.forward(X_batch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "tensor([[0.1002, 0.1005, 0.1003, 0.0996, 0.0991, 0.0999, 0.0990, 0.1004, 0.1008,\n",
            "         0.1005],\n",
            "        [0.0993, 0.0997, 0.0991, 0.1003, 0.1003, 0.0996, 0.1007, 0.0996, 0.1001,\n",
            "         0.0993],\n",
            "        [0.1005, 0.1009, 0.1000, 0.0989, 0.1004, 0.0987, 0.0994, 0.1007, 0.0986,\n",
            "         0.1006],\n",
            "        [0.0990, 0.1008, 0.0988, 0.1015, 0.1020, 0.1004, 0.1023, 0.0990, 0.0987,\n",
            "         0.0971],\n",
            "        [0.0998, 0.0994, 0.0998, 0.1006, 0.0998, 0.0998, 0.1007, 0.1002, 0.0996,\n",
            "         0.0995],\n",
            "        [0.1000, 0.1007, 0.1009, 0.0999, 0.0992, 0.1004, 0.0990, 0.1010, 0.1010,\n",
            "         0.0999],\n",
            "        [0.0990, 0.1008, 0.0988, 0.1015, 0.1020, 0.1004, 0.1023, 0.0990, 0.0987,\n",
            "         0.0971],\n",
            "        [0.1008, 0.0984, 0.1012, 0.0985, 0.0988, 0.1003, 0.0983, 0.1006, 0.1005,\n",
            "         0.1020],\n",
            "        [0.0998, 0.0999, 0.0996, 0.1004, 0.1007, 0.1001, 0.1005, 0.0992, 0.1005,\n",
            "         0.0996],\n",
            "        [0.1016, 0.0988, 0.1015, 0.0988, 0.0978, 0.1004, 0.0977, 0.1005, 0.1014,\n",
            "         0.1044]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.1001, 0.0999, 0.1006, 0.0996, 0.0995, 0.1004, 0.0998, 0.1006, 0.1006,\n",
            "         0.0998],\n",
            "        [0.1006, 0.0991, 0.1001, 0.0990, 0.1000, 0.0998, 0.0989, 0.1001, 0.1000,\n",
            "         0.1012],\n",
            "        [0.0998, 0.0997, 0.1015, 0.0995, 0.0991, 0.0998, 0.0983, 0.1007, 0.1013,\n",
            "         0.1028],\n",
            "        [0.1008, 0.1004, 0.1008, 0.1001, 0.0986, 0.1004, 0.0986, 0.1011, 0.1007,\n",
            "         0.1002],\n",
            "        [0.0997, 0.1008, 0.0988, 0.1008, 0.1021, 0.1000, 0.1016, 0.0990, 0.0977,\n",
            "         0.0982],\n",
            "        [0.0998, 0.0998, 0.0994, 0.1007, 0.0990, 0.1003, 0.1008, 0.0991, 0.0993,\n",
            "         0.0993],\n",
            "        [0.1001, 0.1003, 0.0982, 0.1004, 0.1013, 0.1001, 0.1021, 0.0986, 0.1002,\n",
            "         0.0988],\n",
            "        [0.1007, 0.0993, 0.1007, 0.0987, 0.0993, 0.0994, 0.0983, 0.1013, 0.1006,\n",
            "         0.1011],\n",
            "        [0.0996, 0.1000, 0.1016, 0.0993, 0.0989, 0.0994, 0.0986, 0.1008, 0.1012,\n",
            "         0.1025],\n",
            "        [0.0988, 0.1008, 0.0982, 0.1019, 0.1022, 0.1005, 0.1032, 0.0988, 0.0984,\n",
            "         0.0961]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimehjP6UflH",
        "colab_type": "code",
        "outputId": "ed22ce86-2a67-4923-9f2c-58f22115ae04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fit(cnn,train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 [0/1000 (0%)]\tLoss: 2.302886\t Accuracy:0.000%\n",
            "Epoch : 0 [500/1000 (50%)]\tLoss: 2.302001\t Accuracy:10.392%\n",
            "Epoch : 1 [0/1000 (0%)]\tLoss: 2.301719\t Accuracy:10.000%\n",
            "Epoch : 1 [500/1000 (50%)]\tLoss: 2.302009\t Accuracy:20.392%\n",
            "Epoch : 2 [0/1000 (0%)]\tLoss: 2.301477\t Accuracy:10.000%\n",
            "Epoch : 2 [500/1000 (50%)]\tLoss: 2.301170\t Accuracy:25.098%\n",
            "Epoch : 3 [0/1000 (0%)]\tLoss: 2.299306\t Accuracy:30.000%\n",
            "Epoch : 3 [500/1000 (50%)]\tLoss: 2.297020\t Accuracy:34.314%\n",
            "Epoch : 4 [0/1000 (0%)]\tLoss: 2.292511\t Accuracy:40.000%\n",
            "Epoch : 4 [500/1000 (50%)]\tLoss: 2.294217\t Accuracy:32.941%\n",
            "Epoch : 5 [0/1000 (0%)]\tLoss: 2.267496\t Accuracy:50.000%\n",
            "Epoch : 5 [500/1000 (50%)]\tLoss: 2.207666\t Accuracy:38.824%\n",
            "Epoch : 6 [0/1000 (0%)]\tLoss: 2.172174\t Accuracy:50.000%\n",
            "Epoch : 6 [500/1000 (50%)]\tLoss: 2.037337\t Accuracy:43.725%\n",
            "Epoch : 7 [0/1000 (0%)]\tLoss: 2.154230\t Accuracy:30.000%\n",
            "Epoch : 7 [500/1000 (50%)]\tLoss: 1.921123\t Accuracy:50.588%\n",
            "Epoch : 8 [0/1000 (0%)]\tLoss: 1.951385\t Accuracy:60.000%\n",
            "Epoch : 8 [500/1000 (50%)]\tLoss: 1.941278\t Accuracy:51.765%\n",
            "Epoch : 9 [0/1000 (0%)]\tLoss: 1.811856\t Accuracy:70.000%\n",
            "Epoch : 9 [500/1000 (50%)]\tLoss: 1.957396\t Accuracy:52.745%\n",
            "Epoch : 10 [0/1000 (0%)]\tLoss: 2.021544\t Accuracy:60.000%\n",
            "Epoch : 10 [500/1000 (50%)]\tLoss: 1.924213\t Accuracy:54.902%\n",
            "Epoch : 11 [0/1000 (0%)]\tLoss: 1.752357\t Accuracy:80.000%\n",
            "Epoch : 11 [500/1000 (50%)]\tLoss: 1.847402\t Accuracy:56.078%\n",
            "Epoch : 12 [0/1000 (0%)]\tLoss: 2.029975\t Accuracy:50.000%\n",
            "Epoch : 12 [500/1000 (50%)]\tLoss: 1.860216\t Accuracy:55.098%\n",
            "Epoch : 13 [0/1000 (0%)]\tLoss: 1.661010\t Accuracy:80.000%\n",
            "Epoch : 13 [500/1000 (50%)]\tLoss: 2.095012\t Accuracy:59.216%\n",
            "Epoch : 14 [0/1000 (0%)]\tLoss: 1.658350\t Accuracy:90.000%\n",
            "Epoch : 14 [500/1000 (50%)]\tLoss: 2.194386\t Accuracy:55.098%\n",
            "Epoch : 15 [0/1000 (0%)]\tLoss: 1.942655\t Accuracy:40.000%\n",
            "Epoch : 15 [500/1000 (50%)]\tLoss: 1.955766\t Accuracy:60.392%\n",
            "Epoch : 16 [0/1000 (0%)]\tLoss: 2.132408\t Accuracy:40.000%\n",
            "Epoch : 16 [500/1000 (50%)]\tLoss: 1.748102\t Accuracy:58.824%\n",
            "Epoch : 17 [0/1000 (0%)]\tLoss: 1.927033\t Accuracy:50.000%\n",
            "Epoch : 17 [500/1000 (50%)]\tLoss: 1.902650\t Accuracy:56.863%\n",
            "Epoch : 18 [0/1000 (0%)]\tLoss: 1.936751\t Accuracy:50.000%\n",
            "Epoch : 18 [500/1000 (50%)]\tLoss: 2.231746\t Accuracy:59.216%\n",
            "Epoch : 19 [0/1000 (0%)]\tLoss: 1.749005\t Accuracy:70.000%\n",
            "Epoch : 19 [500/1000 (50%)]\tLoss: 1.852665\t Accuracy:55.294%\n",
            "Epoch : 20 [0/1000 (0%)]\tLoss: 1.976471\t Accuracy:40.000%\n",
            "Epoch : 20 [500/1000 (50%)]\tLoss: 1.949778\t Accuracy:58.627%\n",
            "Epoch : 21 [0/1000 (0%)]\tLoss: 1.979669\t Accuracy:60.000%\n",
            "Epoch : 21 [500/1000 (50%)]\tLoss: 1.843376\t Accuracy:62.941%\n",
            "Epoch : 22 [0/1000 (0%)]\tLoss: 1.843349\t Accuracy:60.000%\n",
            "Epoch : 22 [500/1000 (50%)]\tLoss: 1.761104\t Accuracy:59.608%\n",
            "Epoch : 23 [0/1000 (0%)]\tLoss: 1.865960\t Accuracy:60.000%\n",
            "Epoch : 23 [500/1000 (50%)]\tLoss: 1.936196\t Accuracy:61.961%\n",
            "Epoch : 24 [0/1000 (0%)]\tLoss: 2.129468\t Accuracy:30.000%\n",
            "Epoch : 24 [500/1000 (50%)]\tLoss: 1.964974\t Accuracy:57.843%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAD8CAYAAADt/ZE6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIsQEFCEmoAgxAUX+B/TLN5k5zuqPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_oZH8umUffP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = cnn(*size_input*)\n",
        "# Whats' the input size?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wByaqn-dUfbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.max(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1kUg5cvUy5A",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "\n",
        "* https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiVRueteU0Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}